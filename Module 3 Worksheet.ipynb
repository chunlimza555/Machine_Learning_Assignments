{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuTq8S-cN1rm"
   },
   "source": [
    "## Module 3 Worksheet - Chapters 5 & 6\n",
    "\n",
    "The three checkpoints included in this worksheet need to be completed and marked during your lab session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cu5L-yROg3r"
   },
   "source": [
    "### Checkpoint 1 - California Housing Price Regression\n",
    "\n",
    "Here we use the California Housing dataset available within the Sklearn.\n",
    "\n",
    "This dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).\n",
    "\n",
    "A household is a group of people residing within a home. Since the average number of rooms and bedrooms in this dataset are provided per household, these columns may take surprisingly large values for block groups with few households and many empty houses, such as vacation resorts.\n",
    "\n",
    "The target variable is the median house value for California districts, expressed in hundreds of thousands of dollars ($100,000).\n",
    "\n",
    "This dataset was obtained from the StatLib repository. https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
    "\n",
    "Here we first load the dataset, and print the number of instances and features.\n",
    "\n",
    "```python\n",
    "from sklearn import datasets\n",
    "california = datasets.fetch_california_housing()\n",
    "print('california housing data shape: '+ str(california.data.shape) + \\\n",
    "      '\\nfeature names: ' + str(california.feature_names) + \\\n",
    "      '\\ntarget name: ' + str(california.target_names))\n",
    "```\n",
    "\n",
    "From this, we can see that the dataset contains 20640 instances (housing blocks) and 8 features.\n",
    "We can also call <code>california.DESCR</code> to get more details about the dataset and the definitions for its features.\n",
    "\n",
    "Train a KNN regressor to predict the median house value for a block based on the other available features. Compare what effect changing the following hyperparameters has:\n",
    "- Changing the number of neighbours considered (k=3, k=30, k=300)\n",
    "- Using a distance weighted KNN with the following distance metrics ('euclidean', 'cosine', 'manhattan') \n",
    "\n",
    "**Tips:**\n",
    "- All of the values and labels stored in this dataset are numerical, so there is no need to encode any of the features.\n",
    "- The dataset needs to be split into training and test sets.\n",
    "- Stratifying the train/test split data only works for categorical labels, and so does not need to be performed for regression tasks.\n",
    "- The feature values need to be normalised/standardised.\n",
    "- Think about what measure you will be using to evaluate the effectiveness of your trained models (hint, coefficient of determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "KHiJvuldPRZz",
    "outputId": "adeb6b58-4bb0-43a4-94ef-80328d29f670",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "california housing data shape: (20640, 8)\n",
      "feature names: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "target name: ['MedHouseVal']\n"
     ]
    }
   ],
   "source": [
    "# Enter your code for Checkpoint 1 here\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Check datasets\n",
    "california = datasets.fetch_california_housing()\n",
    "print('california housing data shape: '+ str(california.data.shape) + \\\n",
    "      '\\nfeature names: ' + str(california.feature_names) + \\\n",
    "      '\\ntarget name: ' + str(california.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3.2596    ,   33.        ,    5.0176565 , ...,    3.6918138 ,\n",
       "          32.71      , -117.03      ],\n",
       "       [   3.8125    ,   49.        ,    4.47354497, ...,    1.73809524,\n",
       "          33.77      , -118.16      ],\n",
       "       [   4.1563    ,    4.        ,    5.64583333, ...,    2.72321429,\n",
       "          34.66      , -120.48      ],\n",
       "       ...,\n",
       "       [   2.9344    ,   36.        ,    3.98671727, ...,    3.33206831,\n",
       "          34.03      , -118.38      ],\n",
       "       [   5.7192    ,   15.        ,    6.39534884, ...,    3.17889088,\n",
       "          37.58      , -121.96      ],\n",
       "       [   2.5755    ,   52.        ,    3.40257649, ...,    2.10869565,\n",
       "          37.77      , -122.42      ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set variable to train, test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(california.data, california.target, random_state= 42, test_size= 0.2)\n",
    "\n",
    "# Normalisation Z-Score\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train\n",
    "\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(X_train_scaled, y_train)\n",
    "# print(lr.score(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6443459296530696"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Case 1 : k=3, euclidean, distance\n",
    "knn = KNeighborsRegressor(n_neighbors=3, weights='distance', metric='euclidean')\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6209197121675905"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 1 : k=3, cosine, distance\n",
    "knn = KNeighborsRegressor(n_neighbors=3, weights='distance', metric='cosine')\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6833643014653173"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 1 : k=3, manhattan, distance\n",
    "knn = KNeighborsRegressor(n_neighbors=3, weights='distance', metric='manhattan')\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770326078148411"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2: k=30, euclidean, distance\n",
    "knn = KNeighborsRegressor(n_neighbors=30, weights='distance', metric='euclidean')\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6703612076109324"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2 : k=30, cosine, distance\n",
    "knn = KNeighborsRegressor(n_neighbors=30, weights='distance', metric='cosine')\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7126910553331182"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2 : k=30, manhattan, distance\n",
    "knn = KNeighborsRegressor(n_neighbors=30, weights='distance', metric='manhattan')\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.614592954929857"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 3: k=300, euclidean, distance\n",
    "knn = KNeighborsRegressor(n_neighbors=300, weights='distance', metric='euclidean')\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6196913356146718"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 3 : k=300, cosine, distance\n",
    "knn = KNeighborsRegressor(n_neighbors=300, weights='distance', metric='cosine')\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6402348832641214"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 3 : k=300, manhattan, distance\n",
    "knn = KNeighborsRegressor(n_neighbors=300, weights='distance', metric='manhattan')\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBIBFBKFQRaz"
   },
   "source": [
    "### Checkpoint 2 - Student Performance Prediction\n",
    "\n",
    "Here we use a dataset of student performance in secondary education (high school).\n",
    "More information about this dataset can be found at (https://archive.ics.uci.edu/dataset/320/student+performance).\n",
    "\n",
    "Download the \"student-mat.csv\" file provided on FLO and import the information contained within this csv into a pandas dataframe object (refer to your code from last week's worksheet if you are unsure how to do this).\n",
    "The dataset should have 395 rows and 33 columns.\n",
    "\n",
    "Split the dataset into our labels (\"G3\" column) and input features (everything else).\n",
    "\n",
    "Implement train-test splitting with a test size of 0.2 (random_state=100), to produce the following four variables (X_train, X_test, y_train, y_test). Printing the shapes of these four variables should give the following output:\n",
    "\n",
    "```\n",
    "X_train_shape: (316, 32)\n",
    "X_test_shape: (79, 32)\n",
    "y_train_shape: (316,)\n",
    "y_test_shape: (79,)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "As our dataset features contain categorical feature values, here is the part of our program where we would need to encode our features. Last week we applied a default ordinal encoder to our features, although in hindsight there were two issues with this:\n",
    "1) The exact ordering of our features was not specified (the default is to order the categories alphabetically).\n",
    "2) The features present within our dataset were nominal (not ordinal) so we should have used one-hot-encoding.\n",
    "\n",
    "Looking at the features in our student performance dataset more closely, we see that many of the categorical values are binary but some also contain more than two possible values (e.g., Mjob and Fjob). For these features there is no obvious ordering/ranking of the potential values, so the advised procedure is to apply one-hot-encoding.\n",
    "\n",
    "The simplest way to produce a one-hot-encoded version of a dataset is using the get_dummies function from the pandas library:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "X_train_encoded = pd.get_dummies(X_train)\n",
    "X_test_encoded = pd.get_dummies(X_test)\n",
    "print(X_train_encoded)\n",
    "print(X_test_encoded)\n",
    "```\n",
    "\n",
    "Note, using the get_dummies function assumes that the training and testing datasets always contain the same number of category values for each feature. This requirement may not be satisfied if you have a categorical feature with rare values or if new category values are added. If this happens your encoded training and testing dataset will have a different number of dimentions (columns) from each other. When this occurs you will need to add/remove any additional columns which are not present in both the training and testing datasets. However, for this dataset example the encoded training and testing datasets should have the same number of columns.\n",
    "\n",
    "---\n",
    "\n",
    "Finally, standardise your encoded data, train a Linear Regression model, and evaluate its effectiveness.\n",
    "\n",
    "Compare the performance of the default Linear Regression model against versions involving L1 and L2 regularisation:\n",
    "- Lasso (L1 regularisation) - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "- Ridge (L2 regularisation) - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "- ElasticNet (L1 + L2 regularisation) - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "QESzzG8-HDbV",
    "outputId": "34cf3cb7-66c9-4731-ca2c-24f4611ab80a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395, 33)\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
      "\n",
      "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
      "0      4        3      4     1     1      3        6   5   6   6  \n",
      "1      5        3      3     1     1      3        4   5   5   6  \n",
      "2      4        3      2     2     3      3       10   7   8  10  \n",
      "3      3        2      2     1     1      5        2  15  14  15  \n",
      "4      4        3      2     1     2      5        4   6  10  10  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Enter your code for Checkpoint 2 here\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('student-mat.csv')\n",
    "\n",
    "print(df.shape) \n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split datasets \n",
    "X = df.drop(columns=[\"G3\"])\n",
    "y = df[\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (316, 32)\n",
      "X_test shape: (79, 32)\n",
      "y_train shape: (316,)\n",
      "y_test shape: (79,)\n"
     ]
    }
   ],
   "source": [
    "# Split to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, random_state=100, test_size= 0.2)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)  \n",
    "print(\"X_test shape:\", X_test.shape)    \n",
    "print(\"y_train shape:\", y_train.shape)  \n",
    "print(\"y_test shape:\", y_test.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'school_GP', 'school_MS', 'sex_F', 'sex_M', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'schoolsup_no', 'schoolsup_yes', 'famsup_no', 'famsup_yes', 'paid_no', 'paid_yes', 'activities_no', 'activities_yes', 'nursery_no', 'nursery_yes', 'higher_no', 'higher_yes', 'internet_no', 'internet_yes', 'romantic_no', 'romantic_yes']\n",
      "     age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  \\\n",
      "372   17     2     2           1          3         0       3         4   \n",
      "136   17     3     4           3          2         0       5         4   \n",
      "187   16     2     1           1          2         0       4         2   \n",
      "213   18     2     2           1          2         1       4         4   \n",
      "27    15     4     2           1          1         0       2         2   \n",
      "..   ...   ...   ...         ...        ...       ...     ...       ...   \n",
      "343   17     2     2           1          2         1       3         3   \n",
      "359   18     1     1           2          3         0       5         3   \n",
      "323   17     3     1           1          3         0       3         4   \n",
      "280   17     4     1           2          1         0       4         5   \n",
      "8     15     3     2           1          2         0       4         2   \n",
      "\n",
      "     goout  Dalc  ...  activities_no  activities_yes  nursery_no  nursery_yes  \\\n",
      "372      3     1  ...          False            True       False         True   \n",
      "136      5     2  ...           True           False       False         True   \n",
      "187      3     1  ...          False            True       False         True   \n",
      "213      4     2  ...          False            True       False         True   \n",
      "27       4     2  ...           True           False       False         True   \n",
      "..     ...   ...  ...            ...             ...         ...          ...   \n",
      "343      1     1  ...           True           False       False         True   \n",
      "359      2     1  ...           True           False       False         True   \n",
      "323      3     2  ...           True           False        True        False   \n",
      "280      4     2  ...          False            True       False         True   \n",
      "8        2     1  ...           True           False       False         True   \n",
      "\n",
      "     higher_no  higher_yes  internet_no  internet_yes  romantic_no  \\\n",
      "372      False        True         True         False        False   \n",
      "136      False        True         True         False         True   \n",
      "187      False        True        False          True        False   \n",
      "213      False        True        False          True         True   \n",
      "27       False        True        False          True         True   \n",
      "..         ...         ...          ...           ...          ...   \n",
      "343      False        True        False          True        False   \n",
      "359      False        True        False          True         True   \n",
      "323      False        True        False          True         True   \n",
      "280      False        True        False          True        False   \n",
      "8        False        True        False          True         True   \n",
      "\n",
      "     romantic_yes  \n",
      "372          True  \n",
      "136         False  \n",
      "187          True  \n",
      "213         False  \n",
      "27          False  \n",
      "..            ...  \n",
      "343          True  \n",
      "359         False  \n",
      "323         False  \n",
      "280          True  \n",
      "8           False  \n",
      "\n",
      "[316 rows x 58 columns]\n",
      "     age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  \\\n",
      "188   17     3     3           1          2         0       3         3   \n",
      "365   18     1     3           2          2         0       3         3   \n",
      "190   16     2     3           1          2         0       4         3   \n",
      "353   19     1     1           3          1         1       4         4   \n",
      "166   16     2     2           1          2         0       4         3   \n",
      "..   ...   ...   ...         ...        ...       ...     ...       ...   \n",
      "149   15     2     1           4          1         3       4         5   \n",
      "46    16     3     3           1          2         0       2         3   \n",
      "50    16     2     2           3          2         0       4         3   \n",
      "227   17     2     3           1          2         0       5         3   \n",
      "310   19     1     2           1          2         1       4         2   \n",
      "\n",
      "     goout  Dalc  ...  activities_no  activities_yes  nursery_no  nursery_yes  \\\n",
      "188      3     1  ...           True           False        True        False   \n",
      "365      4     2  ...           True           False       False         True   \n",
      "190      3     1  ...           True           False       False         True   \n",
      "353      4     3  ...           True           False       False         True   \n",
      "166      5     2  ...           True           False       False         True   \n",
      "..     ...   ...  ...            ...             ...         ...          ...   \n",
      "149      5     2  ...           True           False       False         True   \n",
      "46       5     1  ...           True           False       False         True   \n",
      "50       3     2  ...           True           False       False         True   \n",
      "227      3     1  ...           True           False        True        False   \n",
      "310      4     2  ...          False            True        True        False   \n",
      "\n",
      "     higher_no  higher_yes  internet_no  internet_yes  romantic_no  \\\n",
      "188      False        True        False          True        False   \n",
      "365      False        True         True         False         True   \n",
      "190      False        True        False          True         True   \n",
      "353      False        True        False          True         True   \n",
      "166       True       False        False          True         True   \n",
      "..         ...         ...          ...           ...          ...   \n",
      "149      False        True        False          True         True   \n",
      "46       False        True        False          True         True   \n",
      "50       False        True        False          True         True   \n",
      "227      False        True        False          True         True   \n",
      "310      False        True         True         False        False   \n",
      "\n",
      "     romantic_yes  \n",
      "188          True  \n",
      "365         False  \n",
      "190         False  \n",
      "353         False  \n",
      "166         False  \n",
      "..            ...  \n",
      "149         False  \n",
      "46          False  \n",
      "50          False  \n",
      "227         False  \n",
      "310          True  \n",
      "\n",
      "[79 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-Hot to expand string column to more feature columns\n",
    "X_train_encoded = pd.get_dummies(X_train)\n",
    "X_test_encoded = pd.get_dummies(X_test)\n",
    "print(list(X_train_encoded.columns))\n",
    "print(X_train_encoded)\n",
    "print(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7332295233396583"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7567667021007066"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso\n",
    "lasso = Lasso(alpha=0.1)  # Alpha at zero\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "lasso.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7336358409711199"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge\n",
    "ridge = Ridge(alpha=1)  # Alpha at small\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "ridge.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6977540094624292"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ElasticNet L1 + L2\n",
    "elasticnet = ElasticNet(alpha=1)\n",
    "elasticnet.fit(X_train_scaled, y_train)\n",
    "elasticnet.score(X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEb7I91HHems"
   },
   "source": [
    "### Checkpoint 3 - Genome Prediction\n",
    "\n",
    "1) Use appropriate reader function from pandas to read the \"GenomicData.csv\" file provided on FLO. The dataset should have 172 rows and 21053 columns.\n",
    "2) Drop the first two columns as they have redundant information.\n",
    "3) Call the function <code>np.random.seed(42)</code>. This has a type of global effect on any function that uses NumPy and makes your results reproducible across multiple runs.\n",
    "4) Drop any rows that contain a missing (NaN) value. How many instances does this reduce our dataset down to?\n",
    "5) Use the ClassType column as the label (y), and the rest as features (X).\n",
    "6) Split the data into test and train sets, with a 0.25 test size.\n",
    "7) Standardize the features.\n",
    "8) Train two logistic regression models with l1 penalty (use ‘liblinear’ solver) and C = 0:05 and C = 10. What are their accuracies on test data?\n",
    "9) How many features are “selected” (i.e., have non-zero coefficients) in logistic regression with l1 for C = 0:05 and for C = 10? Hint, you can get the coefficient values for a trained LogisticRefression model by calling the <code>.coef_</code> attribute.\n",
    "\n",
    "---\n",
    "\n",
    "Think about whether it makes more sense to drop instances or features with missing values for this dataset.\n",
    "Try both approaches out and see which produces the better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172, 21053)\n",
      "   Unnamed: 0.1  Unnamed: 0       DDR1      RFC2     HSPA6      PAX8  \\\n",
      "0             0  GSM1019138  11.696575  9.498098  6.926517  8.119192   \n",
      "1             1  GSM1019139  10.324599  8.463703  7.473955  7.874865   \n",
      "2             2  GSM1019140  11.416296  7.519654  6.387836  7.983135   \n",
      "3             3  GSM1019141  10.621342  8.555675  8.714281  7.824748   \n",
      "4             4  GSM1019142  10.227293  8.057257  8.236758  8.188167   \n",
      "\n",
      "     GUCA1A      UBA7      THRA    PTPN21  ...  LOC100505794 /// LOC100509111  \\\n",
      "0  3.412547  7.605915  5.287406  5.144362  ...                       4.265834   \n",
      "1  3.328430  8.129946  5.352852  5.608019  ...                       4.213007   \n",
      "2  3.646711  8.583098  5.611202  5.319620  ...                       3.806343   \n",
      "3  4.590441  7.437547  4.943707  5.927861  ...                       4.538299   \n",
      "4  4.062502  8.115143  5.536319  5.310099  ...                       4.568268   \n",
      "\n",
      "   LOC100505562  LOC388210     GALR3    NUS1P3     ITIH4  C1orf175 /// TTC4  \\\n",
      "0      4.959345   6.715859  6.735606  6.747213  5.447054           9.377416   \n",
      "1      4.685613   6.637119  6.655126  5.412674  5.795338           8.626626   \n",
      "2      4.963023   6.939407  6.499424  5.213913  5.458659           8.571116   \n",
      "3      4.893736   6.761510  6.743840  6.288999  5.163930           9.400735   \n",
      "4      5.207185   7.023235  6.803608  7.004808  5.580082           8.802098   \n",
      "\n",
      "   LOC100294402 /// SIGIRR   FAM86B1  ClassType  \n",
      "0                 8.683283  6.336367          3  \n",
      "1                 8.089686  6.563692          1  \n",
      "2                 9.250713  6.835900          1  \n",
      "3                 7.373988  5.743980          3  \n",
      "4                 8.083213  6.872932          3  \n",
      "\n",
      "[5 rows x 21053 columns]\n"
     ]
    }
   ],
   "source": [
    "# Enter your code for Checkpoint 3 here\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('GenomicData.csv')\n",
    "\n",
    "print(df.shape) \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172, 21051)\n",
      "        DDR1      RFC2     HSPA6      PAX8    GUCA1A      UBA7      THRA  \\\n",
      "0  11.696575  9.498098  6.926517  8.119192  3.412547  7.605915  5.287406   \n",
      "1  10.324599  8.463703  7.473955  7.874865  3.328430  8.129946  5.352852   \n",
      "2  11.416296  7.519654  6.387836  7.983135  3.646711  8.583098  5.611202   \n",
      "3  10.621342  8.555675  8.714281  7.824748  4.590441  7.437547  4.943707   \n",
      "4  10.227293  8.057257  8.236758  8.188167  4.062502  8.115143  5.536319   \n",
      "\n",
      "     PTPN21       CCL5    CYP2E1  ...  LOC100505794 /// LOC100509111  \\\n",
      "0  5.144362   8.563300  4.454118  ...                       4.265834   \n",
      "1  5.608019   8.014143  4.797404  ...                       4.213007   \n",
      "2  5.319620   8.858539  4.705669  ...                       3.806343   \n",
      "3  5.927861   9.663748  4.409423  ...                       4.538299   \n",
      "4  5.310099  10.588755  4.421362  ...                       4.568268   \n",
      "\n",
      "   LOC100505562  LOC388210     GALR3    NUS1P3     ITIH4  C1orf175 /// TTC4  \\\n",
      "0      4.959345   6.715859  6.735606  6.747213  5.447054           9.377416   \n",
      "1      4.685613   6.637119  6.655126  5.412674  5.795338           8.626626   \n",
      "2      4.963023   6.939407  6.499424  5.213913  5.458659           8.571116   \n",
      "3      4.893736   6.761510  6.743840  6.288999  5.163930           9.400735   \n",
      "4      5.207185   7.023235  6.803608  7.004808  5.580082           8.802098   \n",
      "\n",
      "   LOC100294402 /// SIGIRR   FAM86B1  ClassType  \n",
      "0                 8.683283  6.336367          3  \n",
      "1                 8.089686  6.563692          1  \n",
      "2                 9.250713  6.835900          1  \n",
      "3                 7.373988  5.743980          3  \n",
      "4                 8.083213  6.872932          3  \n",
      "\n",
      "[5 rows x 21051 columns]\n"
     ]
    }
   ],
   "source": [
    "#  Drop 2 columns \n",
    "df = df.drop(df.columns[:2], axis=1)\n",
    "print(df.shape) \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a default to get the same output everytime, it is similar to random_state = 42\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          DDR1       RFC2     HSPA6      PAX8    GUCA1A      UBA7      THRA  \\\n",
      "0    11.696575   9.498098  6.926517  8.119192  3.412547  7.605915  5.287406   \n",
      "1    10.324599   8.463703  7.473955  7.874865  3.328430  8.129946  5.352852   \n",
      "2    11.416296   7.519654  6.387836  7.983135  3.646711  8.583098  5.611202   \n",
      "3    10.621342   8.555675  8.714281  7.824748  4.590441  7.437547  4.943707   \n",
      "4    10.227293   8.057257  8.236758  8.188167  4.062502  8.115143  5.536319   \n",
      "..         ...        ...       ...       ...       ...       ...       ...   \n",
      "167  10.840880   9.234886  7.520512  8.311986  4.281912  7.634406  6.194104   \n",
      "168  11.275180   8.549333  7.547901  7.876449  3.608414  8.082584  5.974399   \n",
      "169  10.531975   8.044530  6.712938  8.032822  3.934922  7.494316  5.985384   \n",
      "170  11.271373  10.572225  8.287879  8.162460  3.548527  7.578741  5.501066   \n",
      "171  10.702283   9.237732  7.694889  8.628865  3.804980  8.148709  5.936384   \n",
      "\n",
      "       PTPN21       CCL5    CYP2E1  ...  LOC100505794 /// LOC100509111  \\\n",
      "0    5.144362   8.563300  4.454118  ...                       4.265834   \n",
      "1    5.608019   8.014143  4.797404  ...                       4.213007   \n",
      "2    5.319620   8.858539  4.705669  ...                       3.806343   \n",
      "3    5.927861   9.663748  4.409423  ...                       4.538299   \n",
      "4    5.310099  10.588755  4.421362  ...                       4.568268   \n",
      "..        ...        ...       ...  ...                            ...   \n",
      "167  5.224524   8.567465  4.622443  ...                       4.874148   \n",
      "168  5.232199  10.356982  5.193455  ...                       4.568220   \n",
      "169  4.795810   8.945417  4.535639  ...                       4.194476   \n",
      "170  5.207042   9.269407  4.513969  ...                       4.079396   \n",
      "171  5.044347  10.140674  4.247847  ...                       5.447400   \n",
      "\n",
      "     LOC100505562  LOC388210     GALR3    NUS1P3     ITIH4  C1orf175 /// TTC4  \\\n",
      "0        4.959345   6.715859  6.735606  6.747213  5.447054           9.377416   \n",
      "1        4.685613   6.637119  6.655126  5.412674  5.795338           8.626626   \n",
      "2        4.963023   6.939407  6.499424  5.213913  5.458659           8.571116   \n",
      "3        4.893736   6.761510  6.743840  6.288999  5.163930           9.400735   \n",
      "4        5.207185   7.023235  6.803608  7.004808  5.580082           8.802098   \n",
      "..            ...        ...       ...       ...       ...                ...   \n",
      "167      5.195030   6.664152  6.948457  5.438259  5.635322           8.632126   \n",
      "168      4.703689   6.808210  7.016367  5.457348  5.573501           8.258143   \n",
      "169      5.017106   6.808354  6.850351  5.450118  5.762700           8.152625   \n",
      "170      4.653239   6.786010  6.800415  5.806114  5.250638           8.997334   \n",
      "171      4.884840   6.688748  7.085515  5.532114  5.342928           8.725281   \n",
      "\n",
      "     LOC100294402 /// SIGIRR   FAM86B1  ClassType  \n",
      "0                   8.683283  6.336367          3  \n",
      "1                   8.089686  6.563692          1  \n",
      "2                   9.250713  6.835900          1  \n",
      "3                   7.373988  5.743980          3  \n",
      "4                   8.083213  6.872932          3  \n",
      "..                       ...       ...        ...  \n",
      "167                 8.154550  6.730096          1  \n",
      "168                 8.759853  6.194258          3  \n",
      "169                 9.585617  5.578617          1  \n",
      "170                 8.274836  6.167246          3  \n",
      "171                 8.613006  6.264672          1  \n",
      "\n",
      "[172 rows x 19169 columns]\n",
      "(172, 19169)\n"
     ]
    }
   ],
   "source": [
    "# Drop NaN\n",
    "df = df.dropna(axis=1)\n",
    "print(df)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Set up label 'Class Type'\n",
    "y = df[\"ClassType\"]\n",
    "X = df.drop(columns=[\"ClassType\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, random_state=100, test_size= 0.25)\n",
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9534883720930233\n",
      "9\n",
      "C=0.05: Test accuracy=0.9535, Non-zero features=9\n"
     ]
    }
   ],
   "source": [
    "# Train two logistic regression models C=0.05\n",
    "\n",
    "results = {}\n",
    "C = 0.05\n",
    "logr = LogisticRegression(penalty = 'l1', C = C, solver= 'liblinear') # liblinear suites for small datasets.\n",
    "logr.fit(X_train_scaled, y_train)\n",
    "print(logr.score(X_test_scaled, y_test))\n",
    "acc = logr.score(X_test_scaled, y_test)\n",
    "\n",
    "n_selected = np.sum(logr.coef_ != 0)\n",
    "results[C] = {'acc': acc, 'n_selected': n_selected}\n",
    "\n",
    "print(n_selected)\n",
    "print(f'C={C}: Test accuracy={acc:.4f}, Non-zero features={n_selected}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9767441860465116\n",
      "208\n",
      "C=10: Test accuracy=0.9767, Non-zero features=208\n"
     ]
    }
   ],
   "source": [
    "# C=10\n",
    "results = {}\n",
    "C = 10\n",
    "logr = LogisticRegression(penalty = 'l1', C = C, solver= 'liblinear')\n",
    "logr.fit(X_train_scaled, y_train)\n",
    "print(logr.score(X_test_scaled, y_test))\n",
    "acc = logr.score(X_test_scaled, y_test)\n",
    "\n",
    "n_selected = np.sum(logr.coef_ != 0)\n",
    "results[C] = {'acc': acc, 'n_selected': n_selected}\n",
    "\n",
    "print(n_selected)\n",
    "print(f'C={C}: Test accuracy={acc:.4f}, Non-zero features={n_selected}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
